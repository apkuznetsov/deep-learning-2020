{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.python.keras.models import load_model\n",
    "from tensorflow.python.client import device_lib\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8306714144837443\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3129068339\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 11859713732258736786\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(device_lib.list_local_devices())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "curr_folder = \"D:/YandexDisk/datasets/\"\n",
    "\n",
    "path_tokenizer = curr_folder + \"ru-12k-tokenizer-train.pkl\"\n",
    "\n",
    "path_train_dict = curr_folder + \"captions-ru-12k-train.pkl\"\n",
    "path_val_dict = curr_folder + \"captions-ru-12k-val.pkl\"\n",
    "\n",
    "path_features_vgg16 = curr_folder + \"ru-12k-features-vgg16.pkl\"\n",
    "path_features_inception = \"D:/features-inception\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_image_features(filename, data):\n",
    "    all_features = pickle.load(open(filename, 'rb'))\n",
    "    features = {k: all_features[k] for k in data}\n",
    "\n",
    "    return features\n",
    "\n",
    "def to_lines(data):\n",
    "    all_vals = list()\n",
    "    for key in data.keys():\n",
    "        [all_vals.append(d) for d in data[key]]\n",
    "\n",
    "    return all_vals\n",
    "\n",
    "def find_max_words(data):\n",
    "    lines = to_lines(data)\n",
    "    return max(len(l.split()) for l in lines)\n",
    "\n",
    "def load_train_data(train_dict_path, tokenizer_path, features_path):\n",
    "    with open (train_dict_path, 'rb') as f:\n",
    "        out_train_dict = pickle.load(f)\n",
    "    print('кол-во подписей .............. %d' % len(out_train_dict))\n",
    "\n",
    "    out_train_features = load_image_features(features_path, out_train_dict)\n",
    "\n",
    "    with open (tokenizer_path, 'rb') as f:\n",
    "        out_tokenizer = pickle.load(f)\n",
    "    out_vocab_size = len(out_tokenizer.word_index) + 1\n",
    "    print('размер словаря ............... %d' % out_vocab_size)\n",
    "\n",
    "    out_max_words = find_max_words(out_train_dict)\n",
    "    print('длина предложения в словах ... %d' % out_max_words)\n",
    "\n",
    "    return out_train_dict, out_tokenizer, out_vocab_size, out_max_words, out_train_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Наборы для валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "кол-во подписей .............. 2360\n",
      "размер словаря ............... 21391\n",
      "длина предложения в словах ... 21\n"
     ]
    }
   ],
   "source": [
    "val_dict, tokenizer, vocab_size, max_words, val_features = load_train_data(path_val_dict, path_tokenizer, path_features_inception)\n",
    "max_words = 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Оценка модели\n",
    "\n",
    "После того, как модель обучены, мы можем оценить качество её предсказаний в тестовом наборе данных.\n",
    "\n",
    "Мы оценим модель, создав описания для всех изображений в тестовом наборе данных и оценив эти прогнозы с помощью стандартной функции затрат.\n",
    "\n",
    "Во-первых, нам нужно иметь возможность сгенерировать описание изображения, используя обученную модель. Это включает в себя передачу маркера начального описания \"startseq\", генерацию одного слова, а затем рекурсивный вызов модели с сгенерированными словами в качестве входных данных до тех пор, пока не будет достигнут конец маркера последовательности \"endseq\" или не будет достигнута максимальная длина описания.\n",
    "\n",
    "Приведённая ниже функция реализует это поведение и генерирует текстовое описание с учётом обученной модели и заданного подготовленного изображения в качестве входных данных. Эта функция вызывает другую функцию map_int_to_word, чтобы отобразить целочисленное предсказание обратно в слово."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def map_int_to_word(integer, tokenizer):\n",
    "    for word, idx in tokenizer.word_index.items():\n",
    "        if idx == integer:\n",
    "            return word\n",
    "\n",
    "    return None\n",
    "\n",
    "# 0 seed the generation process\n",
    "# 1 iterate over the whole length of the sequence\n",
    "# 2 integer encode input sequence\n",
    "# 3 pad input\n",
    "# 4 predict next word\n",
    "# 5 convert probability to integer\n",
    "# 6 map integer to word\n",
    "# 7 stop if we cannot map the word\n",
    "# 8 append as input for generating the next word\n",
    "# 9 stop if we predict the end of the sequence\n",
    "def generate_caption(model, tokenizer, image, max_words):\n",
    "    in_text = 'startseq'                                    # 0\n",
    "\n",
    "    for i in range(max_words):                              # 1\n",
    "        seq = tokenizer.texts_to_sequences([in_text])[0]    # 2\n",
    "        seq = pad_sequences([seq], maxlen=max_words)        # 3\n",
    "\n",
    "        y_hat = model.predict([image,seq], verbose=0)       # 4\n",
    "        y_hat = np.argmax(y_hat)                            # 5\n",
    "\n",
    "        word = map_int_to_word(y_hat, tokenizer)            # 6\n",
    "        if word is None:                                    # 7\n",
    "            break\n",
    "\n",
    "        in_text += ' ' + word                               # 8\n",
    "\n",
    "        if word == 'endseq':                                # 9\n",
    "            break\n",
    "\n",
    "    return in_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### BLEU\n",
    "\n",
    "Мы сгенерируем предсказания для всех изображений в тестовом наборе данных и в наборе данных для обучения.\n",
    "\n",
    "Приведенная ниже функция с именем evaluate_model() будет оценивать обученную модель по заданному набору подписей изображений и признаков изображений. Фактические и прогнозируемые описания собираются и оцениваются вместе с использованием оценки алгоритма BLEU, который оценивает, насколько сгенерированный текст близок к ожидаемому тексту.\n",
    "\n",
    "BLEU используется при переводе текста для оценки переведённого текста по одному или нескольким другим переводам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, captions, images, tokenizer, max_words):\n",
    "    actual, predicted = list(), list()\n",
    "\n",
    "    for key, captions_list in captions.items():\n",
    "        references = [c.split() for c in captions_list]\n",
    "        y_hat = generate_caption(model, tokenizer, images[key], max_words)\n",
    "\n",
    "        actual.append(references)\n",
    "        predicted.append(y_hat.split())\n",
    "\n",
    "    print('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
    "    print('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
    "    print('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
    "    print('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Оценка VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.361409\n",
      "BLEU-2: 0.193161\n",
      "BLEU-3: 0.137490\n",
      "BLEU-4: 0.055897\n"
     ]
    }
   ],
   "source": [
    "path_model = 'D:/models/vgg16/model-0.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.406490\n",
      "BLEU-2: 0.224477\n",
      "BLEU-3: 0.165109\n",
      "BLEU-4: 0.074745\n"
     ]
    }
   ],
   "source": [
    "path_model = 'D:/models/vgg16/model-1.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.468829\n",
      "BLEU-2: 0.259854\n",
      "BLEU-3: 0.191766\n",
      "BLEU-4: 0.092175\n"
     ]
    }
   ],
   "source": [
    "path_model = 'D:/models/vgg16/model-2.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.512229\n",
      "BLEU-2: 0.289319\n",
      "BLEU-3: 0.215655\n",
      "BLEU-4: 0.107287\n"
     ]
    }
   ],
   "source": [
    "path_model = 'D:/models/vgg16/model-3.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.501154\n",
      "BLEU-2: 0.279348\n",
      "BLEU-3: 0.207381\n",
      "BLEU-4: 0.103278\n"
     ]
    }
   ],
   "source": [
    "path_model = 'D:/models/vgg16/model-4.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.501107\n",
      "BLEU-2: 0.275949\n",
      "BLEU-3: 0.202924\n",
      "BLEU-4: 0.100838\n"
     ]
    }
   ],
   "source": [
    "path_model = 'D:/models/vgg16/model-5.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.494001\n",
      "BLEU-2: 0.268168\n",
      "BLEU-3: 0.196033\n",
      "BLEU-4: 0.095993\n"
     ]
    }
   ],
   "source": [
    "path_model = 'D:/models/vgg16/model-6.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.489138\n",
      "BLEU-2: 0.265169\n",
      "BLEU-3: 0.192033\n",
      "BLEU-4: 0.093191\n"
     ]
    }
   ],
   "source": [
    "path_model = 'D:/models/vgg16/model-7.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.487587\n",
      "BLEU-2: 0.264134\n",
      "BLEU-3: 0.191545\n",
      "BLEU-4: 0.091213\n"
     ]
    }
   ],
   "source": [
    "path_model = 'D:/models/vgg16/model-8.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.482318\n",
      "BLEU-2: 0.260322\n",
      "BLEU-3: 0.188676\n",
      "BLEU-4: 0.088879\n"
     ]
    }
   ],
   "source": [
    "path_model = 'D:/models/vgg16/model-9.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.477577\n",
      "BLEU-2: 0.255085\n",
      "BLEU-3: 0.185947\n",
      "BLEU-4: 0.088144\n"
     ]
    }
   ],
   "source": [
    "path_model = 'D:/models/vgg16/model-10.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.476834\n",
      "BLEU-2: 0.254644\n",
      "BLEU-3: 0.186213\n",
      "BLEU-4: 0.089660\n"
     ]
    }
   ],
   "source": [
    "path_model = 'D:/models/vgg16/model-11.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.473901\n",
      "BLEU-2: 0.252494\n",
      "BLEU-3: 0.183874\n",
      "BLEU-4: 0.087916\n",
      "Wall time: 33min\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "path_model = 'D:/models/vgg16/model-12.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.472866\n",
      "BLEU-2: 0.252232\n",
      "BLEU-3: 0.183842\n",
      "BLEU-4: 0.086977\n",
      "Wall time: 37min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "path_model = 'D:/models/vgg16/model-13.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.464693\n",
      "BLEU-2: 0.247082\n",
      "BLEU-3: 0.180864\n",
      "BLEU-4: 0.086513\n"
     ]
    }
   ],
   "source": [
    "path_model = 'D:/models/model-14.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.463840\n",
      "BLEU-2: 0.247353\n",
      "BLEU-3: 0.181503\n",
      "BLEU-4: 0.088804\n",
      "Wall time: 32min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "path_model = 'D:/models/vgg16/model-15.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.472879\n",
      "BLEU-2: 0.253866\n",
      "BLEU-3: 0.186495\n",
      "BLEU-4: 0.091238\n",
      "Wall time: 33min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "path_model = 'D:/models/vgg16/model-16.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.461818\n",
      "BLEU-2: 0.244349\n",
      "BLEU-3: 0.178495\n",
      "BLEU-4: 0.085330\n",
      "Wall time: 32min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "path_model = 'D:/models/vgg16/model-17.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.459094\n",
      "BLEU-2: 0.242283\n",
      "BLEU-3: 0.176489\n",
      "BLEU-4: 0.083362\n",
      "Wall time: 31min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "path_model = 'D:/models/vgg16/model-18.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.464013\n",
      "BLEU-2: 0.243522\n",
      "BLEU-3: 0.175339\n",
      "BLEU-4: 0.082336\n"
     ]
    }
   ],
   "source": [
    "path_model = 'D:/models/vgg16/model-19.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.446779\n",
      "BLEU-2: 0.227613\n",
      "BLEU-3: 0.163310\n",
      "BLEU-4: 0.073715\n"
     ]
    }
   ],
   "source": [
    "path_model = 'D:/models/vgg16/model-39.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Оценка VGG16-2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.330890\n",
      "BLEU-2: 0.132260\n",
      "BLEU-3: 0.089523\n",
      "BLEU-4: 0.025266\n"
     ]
    }
   ],
   "source": [
    "path_model = 'D:/models/vgg16-2/model-0.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.251889\n",
      "BLEU-2: 0.133708\n",
      "BLEU-3: 0.100575\n",
      "BLEU-4: 0.042080\n",
      "Wall time: 1h 41min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/vgg16-2/model-1.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.333354\n",
      "BLEU-2: 0.182158\n",
      "BLEU-3: 0.135445\n",
      "BLEU-4: 0.059651\n",
      "Wall time: 1h 18min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/vgg16-2/model-2.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.504368\n",
      "BLEU-2: 0.283720\n",
      "BLEU-3: 0.207341\n",
      "BLEU-4: 0.100291\n",
      "Wall time: 56min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/vgg16-2/model-3.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.487142\n",
      "BLEU-2: 0.273837\n",
      "BLEU-3: 0.201340\n",
      "BLEU-4: 0.096789\n",
      "Wall time: 53min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/vgg16-2/model-4.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.503695\n",
      "BLEU-2: 0.287683\n",
      "BLEU-3: 0.213201\n",
      "BLEU-4: 0.106811\n",
      "Wall time: 53min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/vgg16-2/model-5.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.512076\n",
      "BLEU-2: 0.293938\n",
      "BLEU-3: 0.219297\n",
      "BLEU-4: 0.110592\n"
     ]
    }
   ],
   "source": [
    "path_model = 'D:/models/vgg16-2/model-6.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.512135\n",
      "BLEU-2: 0.292193\n",
      "BLEU-3: 0.217427\n",
      "BLEU-4: 0.111023\n",
      "Wall time: 52min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/vgg16-2/model-7.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.511659\n",
      "BLEU-2: 0.289843\n",
      "BLEU-3: 0.216488\n",
      "BLEU-4: 0.110830\n",
      "Wall time: 50min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/vgg16-2/model-8.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.508568\n",
      "BLEU-2: 0.288118\n",
      "BLEU-3: 0.213113\n",
      "BLEU-4: 0.107240\n",
      "Wall time: 49min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/vgg16-2/model-9.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.502268\n",
      "BLEU-2: 0.286105\n",
      "BLEU-3: 0.213294\n",
      "BLEU-4: 0.107053\n",
      "Wall time: 50min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/vgg16-2/model-10.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.504939\n",
      "BLEU-2: 0.287782\n",
      "BLEU-3: 0.215184\n",
      "BLEU-4: 0.108405\n",
      "Wall time: 49min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/vgg16-2/model-11.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.501813\n",
      "BLEU-2: 0.284998\n",
      "BLEU-3: 0.212785\n",
      "BLEU-4: 0.106470\n",
      "Wall time: 51min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/vgg16-2/model-12.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.508468\n",
      "BLEU-2: 0.288323\n",
      "BLEU-3: 0.215613\n",
      "BLEU-4: 0.109824\n",
      "Wall time: 51min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/vgg16-2/model-13.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.501221\n",
      "BLEU-2: 0.284398\n",
      "BLEU-3: 0.211127\n",
      "BLEU-4: 0.105456\n",
      "Wall time: 53min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/vgg16-2/model-14.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.500942\n",
      "BLEU-2: 0.282896\n",
      "BLEU-3: 0.211010\n",
      "BLEU-4: 0.106437\n",
      "Wall time: 51min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/vgg16-2/model-15.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.495775\n",
      "BLEU-2: 0.280361\n",
      "BLEU-3: 0.210769\n",
      "BLEU-4: 0.108840\n",
      "Wall time: 51min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/vgg16-2/model-16.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.494823\n",
      "BLEU-2: 0.279827\n",
      "BLEU-3: 0.209732\n",
      "BLEU-4: 0.107115\n",
      "Wall time: 52min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/vgg16-2/model-17.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.482858\n",
      "BLEU-2: 0.270046\n",
      "BLEU-3: 0.200387\n",
      "BLEU-4: 0.099557\n",
      "Wall time: 51min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/vgg16-2/model-18.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.479654\n",
      "BLEU-2: 0.266615\n",
      "BLEU-3: 0.198103\n",
      "BLEU-4: 0.098578\n",
      "Wall time: 50min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/vgg16-2/model-19.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Оценка Inception"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.308462\n",
      "BLEU-2: 0.147342\n",
      "BLEU-3: 0.102994\n",
      "BLEU-4: 0.039580\n",
      "Wall time: 55min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/inception/model-0.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.401386\n",
      "BLEU-2: 0.206048\n",
      "BLEU-3: 0.148642\n",
      "BLEU-4: 0.066131\n",
      "Wall time: 45min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/inception/model-1.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.465643\n",
      "BLEU-2: 0.249336\n",
      "BLEU-3: 0.183068\n",
      "BLEU-4: 0.087200\n",
      "Wall time: 38min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "path_model = 'D:/models/inception/model-2.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.507810\n",
      "BLEU-2: 0.278442\n",
      "BLEU-3: 0.205553\n",
      "BLEU-4: 0.101472\n",
      "Wall time: 32min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "path_model = 'D:/models/inception/model-3.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.501669\n",
      "BLEU-2: 0.277188\n",
      "BLEU-3: 0.206544\n",
      "BLEU-4: 0.104204\n",
      "Wall time: 36min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "path_model = 'D:/models/inception/model-4.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.491208\n",
      "BLEU-2: 0.269639\n",
      "BLEU-3: 0.200558\n",
      "BLEU-4: 0.100925\n",
      "Wall time: 35min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "path_model = 'D:/models/inception/model-5.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.475721\n",
      "BLEU-2: 0.259377\n",
      "BLEU-3: 0.193260\n",
      "BLEU-4: 0.096344\n",
      "Wall time: 37min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "path_model = 'D:/models/inception/model-6.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.478230\n",
      "BLEU-2: 0.260897\n",
      "BLEU-3: 0.193663\n",
      "BLEU-4: 0.096543\n",
      "Wall time: 38min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "path_model = 'D:/models/inception/model-7.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.484276\n",
      "BLEU-2: 0.264768\n",
      "BLEU-3: 0.195059\n",
      "BLEU-4: 0.096074\n",
      "Wall time: 38min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "path_model = 'D:/models/inception/model-8.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.485589\n",
      "BLEU-2: 0.270567\n",
      "BLEU-3: 0.203022\n",
      "BLEU-4: 0.104512\n",
      "Wall time: 32min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "path_model = 'D:/models/inception/model-9.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.486937\n",
      "BLEU-2: 0.271590\n",
      "BLEU-3: 0.203070\n",
      "BLEU-4: 0.101883\n",
      "Wall time: 38min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "path_model = 'D:/models/inception/model-10.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.484933\n",
      "BLEU-2: 0.269848\n",
      "BLEU-3: 0.201381\n",
      "BLEU-4: 0.100716\n",
      "Wall time: 38min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "path_model = 'D:/models/inception/model-11.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.483060\n",
      "BLEU-2: 0.264644\n",
      "BLEU-3: 0.195287\n",
      "BLEU-4: 0.097009\n",
      "Wall time: 39min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "path_model = 'D:/models/inception/model-12.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.476378\n",
      "BLEU-2: 0.256270\n",
      "BLEU-3: 0.188818\n",
      "BLEU-4: 0.091271\n",
      "Wall time: 35min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "path_model = 'D:/models/inception/model-13.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.462925\n",
      "BLEU-2: 0.241992\n",
      "BLEU-3: 0.176518\n",
      "BLEU-4: 0.082743\n",
      "Wall time: 37min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "path_model = 'D:/models/inception/model-14.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.478496\n",
      "BLEU-2: 0.257831\n",
      "BLEU-3: 0.191438\n",
      "BLEU-4: 0.095683\n",
      "Wall time: 37min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "path_model = 'D:/models/inception/model-15.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.478996\n",
      "BLEU-2: 0.262167\n",
      "BLEU-3: 0.195365\n",
      "BLEU-4: 0.097652\n",
      "Wall time: 35min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "path_model = 'D:/models/inception/model-16.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.465538\n",
      "BLEU-2: 0.250085\n",
      "BLEU-3: 0.184852\n",
      "BLEU-4: 0.091160\n",
      "Wall time: 34min\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "path_model = 'D:/models/inception/model-17.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.471662\n",
      "BLEU-2: 0.252161\n",
      "BLEU-3: 0.185183\n",
      "BLEU-4: 0.089931\n",
      "Wall time: 35min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "path_model = 'D:/models/inception/model-18.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.475187\n",
      "BLEU-2: 0.256462\n",
      "BLEU-3: 0.189255\n",
      "BLEU-4: 0.093866\n",
      "Wall time: 31min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "path_model = 'D:/models/inception/model-19.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Оценка Inception-2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.143182\n",
      "BLEU-2: 0.059739\n",
      "BLEU-3: 0.041356\n",
      "BLEU-4: 0.009241\n",
      "Wall time: 2h 10min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/inception-2/model-0.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.404583\n",
      "BLEU-2: 0.192803\n",
      "BLEU-3: 0.136315\n",
      "BLEU-4: 0.055770\n",
      "Wall time: 1h 2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/inception-2/model-1.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.493209\n",
      "BLEU-2: 0.259008\n",
      "BLEU-3: 0.187620\n",
      "BLEU-4: 0.086226\n",
      "Wall time: 51min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/inception-2/model-2.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.510724\n",
      "BLEU-2: 0.280957\n",
      "BLEU-3: 0.207807\n",
      "BLEU-4: 0.101033\n",
      "Wall time: 53min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/inception-2/model-3.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.506085\n",
      "BLEU-2: 0.274217\n",
      "BLEU-3: 0.202119\n",
      "BLEU-4: 0.098165\n",
      "Wall time: 48min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/inception-2/model-4.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.513603\n",
      "BLEU-2: 0.282965\n",
      "BLEU-3: 0.209564\n",
      "BLEU-4: 0.104223\n",
      "Wall time: 51min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/inception-2/model-5.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.520624\n",
      "BLEU-2: 0.293764\n",
      "BLEU-3: 0.219084\n",
      "BLEU-4: 0.111367\n",
      "Wall time: 50min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/inception-2/model-6.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.515529\n",
      "BLEU-2: 0.289828\n",
      "BLEU-3: 0.215429\n",
      "BLEU-4: 0.109241\n",
      "Wall time: 49min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/inception-2/model-7.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.519564\n",
      "BLEU-2: 0.295451\n",
      "BLEU-3: 0.220886\n",
      "BLEU-4: 0.113214\n",
      "Wall time: 45min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/inception-2/model-8.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.521632\n",
      "BLEU-2: 0.297048\n",
      "BLEU-3: 0.221886\n",
      "BLEU-4: 0.114537\n",
      "Wall time: 48min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/inception-2/model-9.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.511789\n",
      "BLEU-2: 0.286977\n",
      "BLEU-3: 0.212708\n",
      "BLEU-4: 0.106995\n",
      "Wall time: 51min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/inception-2/model-10.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.503644\n",
      "BLEU-2: 0.280418\n",
      "BLEU-3: 0.205865\n",
      "BLEU-4: 0.102691\n",
      "Wall time: 56min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/inception-2/model-11.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.497646\n",
      "BLEU-2: 0.277767\n",
      "BLEU-3: 0.205065\n",
      "BLEU-4: 0.101724\n",
      "Wall time: 55min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/inception-2/model-12.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.491665\n",
      "BLEU-2: 0.274565\n",
      "BLEU-3: 0.201928\n",
      "BLEU-4: 0.098994\n",
      "Wall time: 54min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/inception-2/model-13.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.491949\n",
      "BLEU-2: 0.278453\n",
      "BLEU-3: 0.208454\n",
      "BLEU-4: 0.104314\n",
      "Wall time: 54min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/inception-2/model-14.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.497122\n",
      "BLEU-2: 0.279421\n",
      "BLEU-3: 0.208215\n",
      "BLEU-4: 0.105135\n",
      "Wall time: 54min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/inception-2/model-15.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.491076\n",
      "BLEU-2: 0.274560\n",
      "BLEU-3: 0.204636\n",
      "BLEU-4: 0.104065\n",
      "Wall time: 53min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/inception-2/model-16.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.486741\n",
      "BLEU-2: 0.273443\n",
      "BLEU-3: 0.203743\n",
      "BLEU-4: 0.102320\n",
      "Wall time: 53min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/inception-2/model-17.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.490434\n",
      "BLEU-2: 0.273504\n",
      "BLEU-3: 0.202311\n",
      "BLEU-4: 0.101990\n",
      "Wall time: 52min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/inception-2/model-18.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.490287\n",
      "BLEU-2: 0.274459\n",
      "BLEU-3: 0.204949\n",
      "BLEU-4: 0.105633\n",
      "Wall time: 54min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_model = 'D:/models/inception-2/model-19.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}