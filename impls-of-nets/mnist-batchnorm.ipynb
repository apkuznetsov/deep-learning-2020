{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torchvision.datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "MNIST_train = torchvision.datasets.MNIST('./', download=True, train=True)\n",
    "MNIST_test = torchvision.datasets.MNIST('./', download=True, train=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\programs\\anaconda\\lib\\site-packages\\torchvision\\datasets\\mnist.py:58: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "D:\\programs\\anaconda\\lib\\site-packages\\torchvision\\datasets\\mnist.py:48: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "D:\\programs\\anaconda\\lib\\site-packages\\torchvision\\datasets\\mnist.py:63: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "D:\\programs\\anaconda\\lib\\site-packages\\torchvision\\datasets\\mnist.py:53: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "X_train = MNIST_train.train_data\n",
    "y_train = MNIST_train.train_labels\n",
    "X_test = MNIST_test.test_data\n",
    "y_test = MNIST_test.test_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(60000, 10000)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train), len(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0, :, :])\n",
    "plt.show()\n",
    "print(y_train[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "X_train = X_train.unsqueeze(1).float()\n",
    "X_test = X_test.unsqueeze(1).float()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([60000, 1, 28, 28])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class LeNet5(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 activation='tanh',\n",
    "                 pooling='avg',\n",
    "                 conv_size=5,\n",
    "                 use_batch_norm=False):\n",
    "        super(LeNet5, self).__init__()\n",
    "\n",
    "        self.conv_size = conv_size\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "\n",
    "        if activation == 'tanh':\n",
    "            activation_function = torch.nn.Tanh()\n",
    "        elif activation == 'relu':\n",
    "            activation_function  = torch.nn.ReLU()\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        if pooling == 'avg':\n",
    "            pooling_layer = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        elif pooling == 'max':\n",
    "            pooling_layer  = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        if conv_size == 5:\n",
    "            self.conv1 = torch.nn.Conv2d(\n",
    "                in_channels=1, out_channels=6, kernel_size=5, padding=2)\n",
    "        elif conv_size == 3:\n",
    "            self.conv1_1 = torch.nn.Conv2d(\n",
    "                in_channels=1, out_channels=6, kernel_size=3, padding=1)\n",
    "            self.conv1_2 = torch.nn.Conv2d(\n",
    "                in_channels=6, out_channels=6, kernel_size=3, padding=1)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.act1 = activation_function\n",
    "        self.bn1 = torch.nn.BatchNorm2d(num_features=6)\n",
    "        self.pool1 = pooling_layer\n",
    "\n",
    "        if conv_size == 5:\n",
    "            self.conv2 = self.conv2 = torch.nn.Conv2d(\n",
    "                in_channels=6, out_channels=16, kernel_size=5, padding=0)\n",
    "        elif conv_size == 3:\n",
    "            self.conv2_1 = torch.nn.Conv2d(\n",
    "                in_channels=6, out_channels=16, kernel_size=3, padding=0)\n",
    "            self.conv2_2 = torch.nn.Conv2d(\n",
    "                in_channels=16, out_channels=16, kernel_size=3, padding=0)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.act2 = activation_function\n",
    "        self.bn2 = torch.nn.BatchNorm2d(num_features=16)\n",
    "        self.pool2 = pooling_layer\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(5 * 5 * 16, 120)\n",
    "        self.act3 = activation_function\n",
    "\n",
    "        self.fc2 = torch.nn.Linear(120, 84)\n",
    "        self.act4 = activation_function\n",
    "\n",
    "        self.fc3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.conv_size == 5:\n",
    "            x = self.conv1(x)\n",
    "        elif self.conv_size == 3:\n",
    "            x = self.conv1_2(self.conv1_1(x))\n",
    "        x = self.act1(x)\n",
    "        if self.use_batch_norm:\n",
    "            x = self.bn1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        if self.conv_size == 5:\n",
    "            x = self.conv2(x)\n",
    "        elif self.conv_size == 3:\n",
    "            x = self.conv2_2(self.conv2_1(x))\n",
    "        x = self.act2(x)\n",
    "        if self.use_batch_norm:\n",
    "            x = self.bn2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = x.view(x.size(0), x.size(1) * x.size(2) * x.size(3))\n",
    "        x = self.fc1(x)\n",
    "        x = self.act3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.act4(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9756)\n",
      "tensor(0.9827)\n",
      "tensor(0.9862)\n",
      "tensor(0.9893)\n",
      "tensor(0.9900)\n",
      "tensor(0.9885)\n",
      "tensor(0.9882)\n",
      "tensor(0.9894)\n",
      "tensor(0.9863)\n",
      "tensor(0.9871)\n",
      "tensor(0.9883)\n",
      "tensor(0.9887)\n",
      "tensor(0.9874)\n",
      "tensor(0.9893)\n",
      "tensor(0.9905)\n",
      "tensor(0.9872)\n",
      "tensor(0.9869)\n",
      "tensor(0.9878)\n",
      "tensor(0.9895)\n",
      "tensor(0.9892)\n",
      "tensor(0.9871)\n",
      "tensor(0.9887)\n",
      "tensor(0.9897)\n",
      "tensor(0.9880)\n",
      "tensor(0.9887)\n",
      "tensor(0.9907)\n",
      "tensor(0.9904)\n",
      "tensor(0.9887)\n",
      "tensor(0.9875)\n",
      "tensor(0.9888)\n",
      "---------------\n",
      "tensor(0.9807)\n",
      "tensor(0.9870)\n",
      "tensor(0.9890)\n",
      "tensor(0.9889)\n",
      "tensor(0.9886)\n",
      "tensor(0.9901)\n",
      "tensor(0.9903)\n",
      "tensor(0.9903)\n",
      "tensor(0.9876)\n",
      "tensor(0.9869)\n",
      "tensor(0.9909)\n",
      "tensor(0.9889)\n",
      "tensor(0.9853)\n",
      "tensor(0.9927)\n",
      "tensor(0.9896)\n",
      "tensor(0.9894)\n",
      "tensor(0.9899)\n",
      "tensor(0.9900)\n",
      "tensor(0.9893)\n",
      "tensor(0.9902)\n",
      "tensor(0.9877)\n",
      "tensor(0.9920)\n",
      "tensor(0.9894)\n",
      "tensor(0.9916)\n",
      "tensor(0.9905)\n",
      "tensor(0.9896)\n",
      "tensor(0.9898)\n",
      "tensor(0.9891)\n",
      "tensor(0.9913)\n",
      "tensor(0.9862)\n",
      "---------------\n",
      "tensor(0.9788)\n",
      "tensor(0.9864)\n",
      "tensor(0.9863)\n",
      "tensor(0.9860)\n",
      "tensor(0.9882)\n",
      "tensor(0.9893)\n",
      "tensor(0.9877)\n",
      "tensor(0.9892)\n",
      "tensor(0.9896)\n",
      "tensor(0.9886)\n",
      "tensor(0.9904)\n",
      "tensor(0.9883)\n",
      "tensor(0.9880)\n",
      "tensor(0.9895)\n",
      "tensor(0.9907)\n",
      "tensor(0.9879)\n",
      "tensor(0.9890)\n",
      "tensor(0.9905)\n",
      "tensor(0.9894)\n",
      "tensor(0.9903)\n",
      "tensor(0.9900)\n",
      "tensor(0.9892)\n",
      "tensor(0.9885)\n",
      "tensor(0.9876)\n",
      "tensor(0.9875)\n",
      "tensor(0.9896)\n",
      "tensor(0.9884)\n",
      "tensor(0.9887)\n",
      "tensor(0.9913)\n",
      "tensor(0.9918)\n",
      "---------------\n",
      "tensor(0.9825)\n",
      "tensor(0.9834)\n",
      "tensor(0.9856)\n",
      "tensor(0.9877)\n",
      "tensor(0.9840)\n",
      "tensor(0.9878)\n",
      "tensor(0.9878)\n",
      "tensor(0.9883)\n",
      "tensor(0.9888)\n",
      "tensor(0.9874)\n",
      "tensor(0.9794)\n",
      "tensor(0.9914)\n",
      "tensor(0.9880)\n",
      "tensor(0.9886)\n",
      "tensor(0.9884)\n",
      "tensor(0.9878)\n",
      "tensor(0.9873)\n",
      "tensor(0.9863)\n",
      "tensor(0.9884)\n",
      "tensor(0.9894)\n",
      "tensor(0.9875)\n",
      "tensor(0.9896)\n",
      "tensor(0.9877)\n",
      "tensor(0.9908)\n",
      "tensor(0.9858)\n",
      "tensor(0.9886)\n",
      "tensor(0.9848)\n",
      "tensor(0.9892)\n",
      "tensor(0.9891)\n",
      "tensor(0.9887)\n",
      "---------------\n",
      "tensor(0.9824)\n",
      "tensor(0.9854)\n",
      "tensor(0.9876)\n",
      "tensor(0.9892)\n",
      "tensor(0.9822)\n",
      "tensor(0.9829)\n",
      "tensor(0.9864)\n",
      "tensor(0.9891)\n",
      "tensor(0.9882)\n",
      "tensor(0.9906)\n",
      "tensor(0.9906)\n",
      "tensor(0.9914)\n",
      "tensor(0.9890)\n",
      "tensor(0.9906)\n",
      "tensor(0.9898)\n",
      "tensor(0.9910)\n",
      "tensor(0.9921)\n",
      "tensor(0.9894)\n",
      "tensor(0.9922)\n",
      "tensor(0.9895)\n",
      "tensor(0.9913)\n",
      "tensor(0.9904)\n",
      "tensor(0.9888)\n",
      "tensor(0.9900)\n",
      "tensor(0.9918)\n",
      "tensor(0.9910)\n",
      "tensor(0.9914)\n",
      "tensor(0.9896)\n",
      "tensor(0.9907)\n",
      "tensor(0.9902)\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "def train(net, X_train, y_train, X_test, y_test):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    net = net.to(device)\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=1.0e-3)\n",
    "\n",
    "    batch_size = 100\n",
    "\n",
    "    test_accuracy_history = []\n",
    "    test_loss_history = []\n",
    "\n",
    "    X_test = X_test.to(device)\n",
    "    y_test = y_test.to(device)\n",
    "\n",
    "    for epoch in range(30):\n",
    "        order = np.random.permutation(len(X_train))\n",
    "        for start_index in range(0, len(X_train), batch_size):\n",
    "            optimizer.zero_grad()\n",
    "            net.train()\n",
    "\n",
    "            batch_indexes = order[start_index:start_index+batch_size]\n",
    "\n",
    "            X_batch = X_train[batch_indexes].to(device)\n",
    "            y_batch = y_train[batch_indexes].to(device)\n",
    "\n",
    "            preds = net.forward(X_batch)\n",
    "\n",
    "            loss_value = loss(preds, y_batch)\n",
    "            loss_value.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "        net.eval()\n",
    "        test_preds = net.forward(X_test)\n",
    "        test_loss_history.append(loss(test_preds, y_test).data.cpu())\n",
    "\n",
    "        accuracy = (test_preds.argmax(dim=1) == y_test).float().mean().data.cpu()\n",
    "        test_accuracy_history.append(accuracy)\n",
    "\n",
    "        print(accuracy)\n",
    "    print('---------------')\n",
    "    return test_accuracy_history, test_loss_history\n",
    "\n",
    "accuracies = {}\n",
    "losses = {}\n",
    "\n",
    "accuracies['tanh'], losses['tanh'] = train(LeNet5(activation='tanh', conv_size=5),\n",
    "          X_train, y_train, X_test, y_test)\n",
    "\n",
    "accuracies['relu'], losses['relu'] = train(LeNet5(activation='relu', conv_size=5),\n",
    "          X_train, y_train, X_test, y_test)\n",
    "\n",
    "accuracies['relu_3'], losses['relu_3'] = train(LeNet5(activation='relu', conv_size=3),\n",
    "                                               X_train, y_train, X_test, y_test)\n",
    "\n",
    "accuracies['relu_3_max_pool'], losses['relu_3_max_pool'] = train(LeNet5(activation='relu', conv_size=3, pooling='max'),\n",
    "          X_train, y_train, X_test, y_test)\n",
    "\n",
    "accuracies['relu_3_max_pool_bn'], losses['relu_3_max_pool_bn'] = train(LeNet5(activation='relu', conv_size=3, pooling='max', use_batch_norm=True),\n",
    "          X_train, y_train, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}